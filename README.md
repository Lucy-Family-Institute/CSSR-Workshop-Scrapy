# Scrape Webpage with Python
Author: Yang Xu (yxu6@nd.edu)

## Overview

This is the introduction of the Workshop offered by Lucy Family Institute - Center for Social Science Research.

Scrapy is a fast high-level web crawling and web scraping Python framework, used to crawl websites and extract structured data from their pages. It can be used for a wide range of purposes, from data mining to monitoring and automated testing.

The workshop provides an introduction to web scraping, and involves a hands-on project to scrape, parse and extract desired data from a webpage using Scrapy.

Participants will learn:
1. Grasp web scraping fundamentals.
2. Master the art of HTML parsing and extracting data.
3. Use regex for precise data retrieval.
4. Set up Scrapy for efficient data extraction.

## Prior Knowledge

The workshop assumes the working knowledge of Python. It is recommended to have at least 50 hours experience in programming. There are links to some useful Python basics below. The workshop will **NOT** go through Python introduction.

## Software Details

Make sure the Python3 (recommended version 3.9 or later) and IDE (recommended Jupyter) are installed.

You can refer to the [Python_IDE_Setup](https://github.com/Lucy-Family-Institute/CSSR-Workshop-Scrapy/blob/master/Python_IDE_Setup.md) to install the required apps.

The packages this workshop will use are:
1. Scrapy 
2. Pandas
3. BeautifulSoup

You can install them through pip3 or conda. It will be demonstrated at the beginning of the workshop.

## IMPORTANT INFORMATION

Web scraping is, in general, legal, given the scraping instance follows the **Terms of Service** of the targeted website, as well as the data is public. A good practice is to check the robots.txt of the website to be scraped.

Popular social media website such as Twitter, Facebook, Instagram have their own policy, some may offer API for direct data exchange.

In addition, websites listed below are out of the scope of this workshop:

1. Websites with paywall, such as: WSJ, New York Times, etc.
2. Websites deployed with CAPTCHA.
3. Data that requires credentials for access.
4. Google suite, such as Google Search, Google Map, etc.
5. Other websites that prohibits automated HTTP requests.
6. Data rendered by javascript

## Workshop Plan and Date

The workshop is planned with an 1.5 hours session. Including a brief introduction, live demos. The instructor will answer questions and help with the debug during live-coding.

3:30-5pm Oct.3 CDS 246 (Hesburgh Library)